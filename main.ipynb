{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "\n",
    "audio_folderpath = \"C:/Users/anany/Cambridge/Part II Project/data/raw\"\n",
    "image_folderpath = \"C:/Users/anany\\Cambridge\\Part II Project\\data\\images\"\n",
    "split_ratio = 0.75\n",
    "image_type = \"spectrogram\"\n",
    "clip_length = 10\n",
    "shift_length = 5\n",
    "resize_dim = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category list\n",
    "\n",
    "genre_id = {}\n",
    "\n",
    "\n",
    "for genre in os.listdir(audio_folderpath):\n",
    "    i = 1\n",
    "    while (genre[:i] in genre_id.values() and i <= len(genre)):\n",
    "        i += 1\n",
    "    genre_id[genre] = genre[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ids and create song dictionary\n",
    "\n",
    "audio_dict = {}\n",
    "\n",
    "for genre in genre_id:\n",
    "    files = os.listdir(os.path.join(audio_folderpath, genre))\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        filepath = os.path.join(audio_folderpath, genre, file)\n",
    "        id = genre_id[genre] + '{:03d}'.format(count)\n",
    "        count += 1\n",
    "        audio_dict[id] = filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "\n",
    "id_list = list(audio_dict.keys())\n",
    "random.shuffle(id_list)\n",
    "split_index = int(split_ratio * len(id_list))\n",
    "\n",
    "train_set = id_list[:split_index]\n",
    "test_set = id_list[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_new import *\n",
    "\n",
    "\n",
    "def get_image_func(image_type):\n",
    "    if image_type == \"spectrogram\":\n",
    "        return wav_to_spectrogram\n",
    "    elif image_type == \"chromagram\":\n",
    "        return wav_to_chromagram\n",
    "    elif image_type == \"mfcc\":\n",
    "        return wav_to_mfcc\n",
    "    elif image_type == \"cochleagram\":\n",
    "        return wav_to_cochleagram\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "\n",
    "to_image = get_image_func(image_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cp.cuda.runtime.getDeviceCount()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cp.cuda.runtime.getDeviceCount()'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHOUT GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "     1\n",
      "0\n",
      "     0\n",
      "     1\n",
      "1\n",
      "     0\n",
      "     1\n",
      "2\n",
      "     0\n",
      "     1\n",
      "3\n",
      "     0\n",
      "     1\n",
      "4\n",
      "     0\n",
      "     1\n",
      "5\n",
      "     0\n",
      "     1\n",
      "6\n",
      "     0\n",
      "     1\n",
      "7\n",
      "     0\n",
      "     1\n",
      "8\n",
      "     0\n",
      "     1\n",
      "9\n",
      "     0\n",
      "     1\n",
      "10\n",
      "     0\n",
      "     1\n",
      "11\n",
      "     0\n",
      "     1\n",
      "12\n",
      "     0\n",
      "     1\n",
      "13\n",
      "     0\n",
      "     1\n",
      "14\n",
      "     0\n",
      "     1\n",
      "15\n",
      "     0\n",
      "     1\n",
      "16\n",
      "     0\n",
      "     1\n",
      "17\n",
      "     0\n",
      "     1\n",
      "18\n",
      "     0\n",
      "     1\n",
      "19\n",
      "     0\n",
      "     1\n",
      "20\n",
      "     0\n",
      "     1\n",
      "21\n",
      "     0\n",
      "     1\n",
      "22\n",
      "     0\n",
      "     1\n",
      "23\n",
      "     0\n",
      "     1\n",
      "24\n",
      "     0\n",
      "     1\n",
      "25\n",
      "     0\n",
      "     1\n",
      "26\n",
      "     0\n",
      "     1\n",
      "27\n",
      "     0\n",
      "     1\n",
      "28\n",
      "     0\n",
      "     1\n",
      "29\n",
      "     0\n",
      "     1\n",
      "30\n",
      "     0\n",
      "     1\n",
      "31\n",
      "     0\n",
      "     1\n",
      "32\n",
      "     0\n",
      "     1\n",
      "33\n",
      "     0\n",
      "     1\n",
      "34\n",
      "     0\n",
      "     1\n",
      "35\n",
      "     0\n",
      "     1\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "'''TRAIN SET'''\n",
    "\n",
    "train_ids = None\n",
    "train_imgs = None\n",
    "train_labels = None\n",
    "\n",
    "label_list = list(genre_id.values())\n",
    "\n",
    "count = 0\n",
    "for id in train_set:\n",
    "    filepath = audio_dict[id]\n",
    "\n",
    "    # Convert to image(whole) - this is an object NOT a file\n",
    "    images = to_image(filepath)\n",
    "\n",
    "    # Feed image objects into splitting function\n",
    "    for i in range(2):\n",
    "        # Dictionary mapping audio sample id to audio sample data\n",
    "        img_dict = split(images[i], id + \"_ch\" + str(i), clip_length, shift_length, resize_dim)\n",
    "        \n",
    "        # Set/update audio sample id list\n",
    "        if train_ids is None:\n",
    "            train_ids = list(img_dict.keys())\n",
    "        else:\n",
    "            train_ids.extend(list(img_dict.keys()))\n",
    "\n",
    "\n",
    "\n",
    "        # Set/update array of image arrays\n",
    "        if train_imgs is None:\n",
    "            train_imgs = cp.array(list(img_dict.values()))\n",
    "        else:\n",
    "            train_imgs = cp.append(train_imgs, list(img_dict.values()), axis = 0)\n",
    "\n",
    "        print(\"    \", i)\n",
    "        #train_imgs.extend(list(img_dict.values()))\n",
    "    print(count)\n",
    "    count += 1\n",
    "    \n",
    "new_train_labels = np.array([label_list.index(x.split('_')[0][:-3]) for x in train_ids])\n",
    "if train_labels is None:\n",
    "    train_labels = new_train_labels\n",
    "else:\n",
    "    train_labels = cp.append(train_labels, new_train_labels, axis = 0)\n",
    "\n",
    "        \n",
    "\n",
    "     \n",
    "\n",
    "    # TODO: resize, color regularize or something\n",
    "#train_imgs_resized = [x.resize((resize_dim, resize_dim)) for x in train_imgs]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2745098 , 0.05882353, 0.38431373, 1.        ],\n",
       "        [0.28235294, 0.07058824, 0.4       , 1.        ],\n",
       "        [0.24705882, 0.11764706, 0.41960784, 1.        ],\n",
       "        ...,\n",
       "        [0.14117647, 0.66666667, 0.50980392, 1.        ],\n",
       "        [0.15294118, 0.68235294, 0.50196078, 1.        ],\n",
       "        [0.28235294, 0.73333333, 0.42745098, 1.        ]],\n",
       "\n",
       "       [[0.2745098 , 0.05490196, 0.38039216, 1.        ],\n",
       "        [0.28235294, 0.06666667, 0.39607843, 1.        ],\n",
       "        [0.24705882, 0.11372549, 0.41568627, 1.        ],\n",
       "        ...,\n",
       "        [0.14901961, 0.67058824, 0.50588235, 1.        ],\n",
       "        [0.15686275, 0.68627451, 0.49803922, 1.        ],\n",
       "        [0.27058824, 0.72941176, 0.43529412, 1.        ]],\n",
       "\n",
       "       [[0.2745098 , 0.04313725, 0.37254902, 1.        ],\n",
       "        [0.27843137, 0.05098039, 0.38039216, 1.        ],\n",
       "        [0.25098039, 0.10588235, 0.40784314, 1.        ],\n",
       "        ...,\n",
       "        [0.16862745, 0.68627451, 0.49411765, 1.        ],\n",
       "        [0.17647059, 0.69803922, 0.48627451, 1.        ],\n",
       "        [0.23921569, 0.72156863, 0.45098039, 1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        ...,\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ]],\n",
       "\n",
       "       [[0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        ...,\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ]],\n",
       "\n",
       "       [[0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        ...,\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "     1\n",
      "0\n",
      "     0\n",
      "     1\n",
      "1\n",
      "     0\n",
      "     1\n",
      "2\n",
      "     0\n",
      "     1\n",
      "3\n",
      "     0\n",
      "     1\n",
      "4\n",
      "     0\n",
      "     1\n",
      "5\n",
      "     0\n",
      "     1\n",
      "6\n",
      "     0\n",
      "     1\n",
      "7\n",
      "     0\n",
      "     1\n",
      "8\n",
      "     0\n",
      "     1\n",
      "9\n",
      "     0\n",
      "     1\n",
      "10\n",
      "     0\n",
      "     1\n",
      "11\n",
      "     0\n",
      "     1\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "'''TEST SET'''\n",
    "\n",
    "test_ids = None\n",
    "test_imgs = None\n",
    "test_labels = None\n",
    "\n",
    "label_list = list(genre_id.values())\n",
    "\n",
    "count = 0\n",
    "for id in test_set:\n",
    "    filepath = audio_dict[id]\n",
    "\n",
    "    # Convert to image(whole) - this is an object NOT a file\n",
    "    images = to_image(filepath)\n",
    "\n",
    "    # Feed image objects into splitting function\n",
    "    for i in range(2):\n",
    "        # Dictionary mapping audio sample id to audio sample data\n",
    "        img_dict = split(images[i], id + \"_ch\" + str(i), clip_length, shift_length, resize_dim)\n",
    "        \n",
    "        # Set/update audio sample id list\n",
    "        if test_ids is None:\n",
    "            test_ids = list(img_dict.keys())\n",
    "        else:\n",
    "            test_ids.extend(list(img_dict.keys()))\n",
    "\n",
    "\n",
    "\n",
    "        # Set/update array of image arrays\n",
    "        if test_imgs is None:\n",
    "            test_imgs = cp.array(list(img_dict.values()))\n",
    "        else:\n",
    "            test_imgs = cp.append(test_imgs, list(img_dict.values()), axis = 0)\n",
    "\n",
    "        print(\"    \", i)\n",
    "    print(count)\n",
    "    count += 1\n",
    "    \n",
    "new_test_labels = np.array([label_list.index(x.split('_')[0][:-3]) for x in test_ids])\n",
    "if test_labels is None:\n",
    "    test_labels = new_test_labels\n",
    "else:\n",
    "    test_labels = cp.append(test_labels, new_test_labels, axis = 0)\n",
    "\n",
    "        \n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myarray = (test_imgs[10] * 255).astype(np.uint8)\\n\\nImage.fromarray(np.array(myarray.get()))'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''myarray = (test_imgs[10] * 255).astype(np.uint8)\n",
    "\n",
    "Image.fromarray(np.array(myarray.get()))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(len(test_ids))\\nprint(test_labels.shape)\\nprint(test_imgs.shape)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(len(test_ids))\n",
    "print(test_labels.shape)\n",
    "print(test_imgs.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myarray = train_imgs[0].shape\\n\\nfrom PIL import Image\\nfrom matplotlib import cm\\nim = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''myarray = train_imgs[0].shape\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# TODO: iterate, convert, add to correct set\\n\\nx_train = cp.asarray([cp.asarray(x) for x in train_imgs_resized]) / 255.0\\ny_train = cp.asarray(train_labels)\\nx_test = cp.asarray([cp.asarray(x) for x in test_imgs_resized]) / 255.0\\ny_test = cp.asarray(test_labels)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# TODO: iterate, convert, add to correct set\n",
    "\n",
    "x_train = cp.asarray([cp.asarray(x) for x in train_imgs_resized]) / 255.0\n",
    "y_train = cp.asarray(train_labels)\n",
    "x_test = cp.asarray([cp.asarray(x) for x in test_imgs_resized]) / 255.0\n",
    "y_test = cp.asarray(test_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train = train_imgs.get()\\ny_train = train_labels\\nx_test = test_imgs.get()\\ny_test = test_labels'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_train = train_imgs.get()\n",
    "y_train = train_labels\n",
    "x_test = test_imgs.get()\n",
    "y_test = test_labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\n\\nfrom tensorflow.keras import datasets, layers, models\\nimport matplotlib.pyplot as plt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = models.Sequential()\\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train[0].shape))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train[0].shape))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model.add(layers.Flatten())\\nmodel.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(10))\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model.compile(optimizer='adam',\\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\\n              metrics=['accuracy'])\\n\\nhistory = model.fit(x_train, y_train, epochs=5, \\n                    validation_data=(x_test, y_test))\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, \n",
    "                    validation_data=(x_test, y_test))'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_gen():\n",
    "\n",
    "    label_list = list(genre_id.values())\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        for id in train_set:\n",
    "            filepath = audio_dict[id]\n",
    "\n",
    "            train_ids = None\n",
    "            train_imgs = None\n",
    "            train_labels = None\n",
    "\n",
    "            # Convert to image(whole) - this is an object NOT a file\n",
    "            images = to_image(filepath)\n",
    "\n",
    "            # Feed image objects into splitting function\n",
    "            for i in range(2):\n",
    "                # Dictionary mapping audio sample id to audio sample data\n",
    "                img_dict = split(images[i], id + \"_ch\" + str(i), clip_length, shift_length, resize_dim)\n",
    "                \n",
    "                # Set/update audio sample id list\n",
    "                if train_ids is None:\n",
    "                    train_ids = list(img_dict.keys())\n",
    "                else:\n",
    "                    train_ids.extend(list(img_dict.keys()))\n",
    "\n",
    "\n",
    "                # Set/update array of image arrays\n",
    "                if train_imgs is None:\n",
    "                    train_imgs = np.array(list(img_dict.values()))\n",
    "                else:\n",
    "                    train_imgs = np.append(train_imgs, np.array(list(img_dict.values())), axis = 0)\n",
    "\n",
    "                #print(\"    \", i)\n",
    "                #train_imgs.extend(list(img_dict.values()))\n",
    "            #print(count)\n",
    "            count += 1\n",
    "            \n",
    "            train_labels = np.array([label_list.index(x.split('_')[0][:-3]) for x in train_ids])\n",
    "\n",
    "            yield train_imgs, train_labels\n",
    "    \n",
    "        print(\"END TRAIN\")\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen():\n",
    "    test_ids = None\n",
    "    test_imgs = None\n",
    "    test_labels = None\n",
    "\n",
    "    label_list = list(genre_id.values())\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "\n",
    "        for id in test_set:\n",
    "            filepath = audio_dict[id]\n",
    "\n",
    "            # Convert to image(whole) - this is an object NOT a file\n",
    "            images = to_image(filepath)\n",
    "\n",
    "            # Feed image objects into splitting function\n",
    "            for i in range(2):\n",
    "                # Dictionary mapping audio sample id to audio sample data\n",
    "                img_dict = split(images[i], id + \"_ch\" + str(i), clip_length, shift_length, resize_dim)\n",
    "                \n",
    "                # Set/update audio sample id list\n",
    "                if test_ids is None:\n",
    "                    test_ids = list(img_dict.keys())\n",
    "                else:\n",
    "                    test_ids.extend(list(img_dict.keys()))\n",
    "\n",
    "\n",
    "\n",
    "                # Set/update array of image arrays\n",
    "                if test_imgs is None:\n",
    "                    test_imgs = np.array(list(img_dict.values()))\n",
    "                else:\n",
    "                    test_imgs = np.append(test_imgs, np.array(list(img_dict.values())), axis = 0)\n",
    "\n",
    "                #print(\"    \", i)\n",
    "            #print(count)\n",
    "            count += 1\n",
    "            \n",
    "            test_labels = np.array([label_list.index(x.split('_')[0][:-3]) for x in test_ids])\n",
    "\n",
    "            yield test_imgs, test_labels\n",
    "        \n",
    "        print(\"END TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(resize_dim, resize_dim, 4)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3/3 [==============================] - 35s 15s/step - loss: 48.1456 - accuracy: 0.0000e+00 - val_loss: 20.3622 - val_accuracy: 0.1954\n",
      "Epoch 2/8\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.7845 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_gen(),\n",
    "                    steps_per_epoch=3,\n",
    "                              epochs=8,\n",
    "                              validation_data=test_gen(),\n",
    "                              validation_steps=3\n",
    "                              )\n",
    "\n",
    "'''history = model.fit(x_train, y_train, epochs=5, \n",
    "                    validation_data=(x_test, y_test))'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.activation import Tanh, Sigmoid\n",
    "from cnn.convolutional import Convolutional\n",
    "from cnn.dense import Dense\n",
    "from cnn.loss import MSE, MSE_prime, binary_cross_entropy, binary_cross_entropy_prime\n",
    "from cnn.nn import MNIST\n",
    "from cnn.reshape import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folderpath = \"C:/Users/anany/Cambridge/Part II Project/data/raw\"\n",
    "image_folderpath = \"C:/Users/anany\\Cambridge\\Part II Project\\data\\images\"\n",
    "split_ratio = 0.75\n",
    "image_type = \"spectrogram\"\n",
    "clip_length = 10\n",
    "shift_length = 500\n",
    "resize_dim = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 0, 0, 4, 4, 0, 0, 4, 4, 2, 2, 1, 1, 4, 4, 0, 0, 3, 3,\n",
       "       3, 3, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_ids\n",
    "# train_imgs\n",
    "# train_labels\n",
    "\n",
    "# test_ids\n",
    "# test_imgs\n",
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 1, 28, 28, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = train_imgs.reshape((74, 1, 28, 28, 4))\n",
    "\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [\n",
    "        Convolutional(input_shape=(1, 28, 28, 4), kernel_size=3, depth=5), # output_shape=()\n",
    "        Sigmoid()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m c \u001b[39m=\u001b[39m Convolutional(input_shape\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m4\u001b[39;49m), kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, depth\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m), \u001b[39m# output_shape=()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anany\\Cambridge\\Part II Project\\part_ii_project\\cnn\\convolutional.py:7\u001b[0m, in \u001b[0;36mConvolutional.__init__\u001b[1;34m(self, input_shape, kernel_size, depth)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_shape, kernel_size, depth):\n\u001b[1;32m----> 7\u001b[0m     input_depth, input_height, input_width \u001b[39m=\u001b[39m input_shape\n\u001b[0;32m      9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth \u001b[39m=\u001b[39m depth\n\u001b[0;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_shape \u001b[39m=\u001b[39m input_shape\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "c = Convolutional(input_shape=(1, 28, 28, 4), kernel_size=3, depth=5), # output_shape=()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.1\n",
    "\n",
    "for e in range(epochs):\n",
    "    error = 0\n",
    "\n",
    "    temp = zip(x_train, y_train)\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        output = x\n",
    "        for layer in network:\n",
    "            output = layer.forward(output)\n",
    "        \n",
    "        error += binary_cross_entropy(y, output)\n",
    "\n",
    "        grad = binary_cross_entropy_prime(y, output)\n",
    "        for layer in reversed(network):\n",
    "            grad = layer.backward(grad, learning_rate)\n",
    "    \n",
    "    error /= len(x_train)\n",
    "    print(f\"{e + 1}/{epochs}, error = {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20, error = 0.29174904351223846\n",
      "2/20, error = 0.06523393893289796\n",
      "3/20, error = 0.04482472830743084\n",
      "4/20, error = 0.017893832092078333\n",
      "5/20, error = 0.010019754374280758\n",
      "6/20, error = 0.007956868974355146\n",
      "7/20, error = 0.006365971128654754\n",
      "8/20, error = 0.005518842253885437\n",
      "9/20, error = 0.004870873720918497\n",
      "10/20, error = 0.004377086567407643\n",
      "11/20, error = 0.003980103157568912\n",
      "12/20, error = 0.003652179398251721\n",
      "13/20, error = 0.0033757917537399974\n",
      "14/20, error = 0.003139399227425653\n",
      "15/20, error = 0.00293487950356693\n",
      "16/20, error = 0.0027562031446883035\n",
      "17/20, error = 0.002598730915025944\n",
      "18/20, error = 0.0024588323912226825\n",
      "19/20, error = 0.0023336445914558137\n",
      "20/20, error = 0.0022208939011593145\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 1, true: 1\n",
      "pred: 0, true: 0\n"
     ]
    }
   ],
   "source": [
    "MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[1, 1, 1],\n",
       "        [1, 1, 1]],\n",
       "\n",
       "       [[2, 2, 2],\n",
       "        [2, 2, 2]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]]])\n",
    "# 2 3 4\n",
    "\n",
    "new_arr = np.moveaxis(arr, 2, 0)\n",
    "# 4 3 2\n",
    "\n",
    "new_arr[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2627451 , 0.30588235, 0.40784314, 1.        ],\n",
       "        [0.29803922, 0.74117647, 0.42745098, 1.        ],\n",
       "        [0.30196078, 0.7254902 , 0.42745098, 1.        ],\n",
       "        ...,\n",
       "        [0.34117647, 0.77647059, 0.39607843, 1.        ],\n",
       "        [0.21176471, 0.71372549, 0.47058824, 1.        ],\n",
       "        [0.18431373, 0.69411765, 0.48627451, 1.        ]],\n",
       "\n",
       "       [[0.21176471, 0.25098039, 0.41960784, 1.        ],\n",
       "        [0.11372549, 0.58431373, 0.55294118, 1.        ],\n",
       "        [0.14509804, 0.58431373, 0.53333333, 1.        ],\n",
       "        ...,\n",
       "        [0.21176471, 0.70980392, 0.47058824, 1.        ],\n",
       "        [0.17647059, 0.6745098 , 0.49411765, 1.        ],\n",
       "        [0.14509804, 0.63921569, 0.51764706, 1.        ]],\n",
       "\n",
       "       [[0.21568627, 0.23921569, 0.42352941, 1.        ],\n",
       "        [0.13333333, 0.55686275, 0.55686275, 1.        ],\n",
       "        [0.14901961, 0.56862745, 0.53333333, 1.        ],\n",
       "        ...,\n",
       "        [0.12156863, 0.57647059, 0.54901961, 1.        ],\n",
       "        [0.1254902 , 0.56470588, 0.54901961, 1.        ],\n",
       "        [0.1254902 , 0.56470588, 0.54901961, 1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.26666667, 0.03921569, 0.36078431, 1.        ],\n",
       "        [0.26666667, 0.01176471, 0.3372549 , 1.        ],\n",
       "        [0.26666667, 0.01960784, 0.34117647, 1.        ],\n",
       "        ...,\n",
       "        [0.2627451 , 0.02352941, 0.34117647, 1.        ],\n",
       "        [0.26666667, 0.01176471, 0.33333333, 1.        ],\n",
       "        [0.26666667, 0.05882353, 0.37254902, 1.        ]],\n",
       "\n",
       "       [[0.26666667, 0.01568627, 0.34117647, 1.        ],\n",
       "        [0.26666667, 0.00784314, 0.33333333, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        ...,\n",
       "        [0.26666667, 0.00784314, 0.33333333, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00784314, 0.3372549 , 1.        ]],\n",
       "\n",
       "       [[0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        ...,\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ],\n",
       "        [0.26666667, 0.00392157, 0.32941176, 1.        ]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2627451 , 0.29803922, 0.30196078, ..., 0.34117647,\n",
       "         0.21176471, 0.18431373],\n",
       "        [0.21176471, 0.11372549, 0.14509804, ..., 0.21176471,\n",
       "         0.17647059, 0.14509804],\n",
       "        [0.21568627, 0.13333333, 0.14901961, ..., 0.12156863,\n",
       "         0.1254902 , 0.1254902 ],\n",
       "        ...,\n",
       "        [0.26666667, 0.26666667, 0.26666667, ..., 0.2627451 ,\n",
       "         0.26666667, 0.26666667],\n",
       "        [0.26666667, 0.26666667, 0.26666667, ..., 0.26666667,\n",
       "         0.26666667, 0.26666667],\n",
       "        [0.26666667, 0.26666667, 0.26666667, ..., 0.26666667,\n",
       "         0.26666667, 0.26666667]],\n",
       "\n",
       "       [[0.30588235, 0.74117647, 0.7254902 , ..., 0.77647059,\n",
       "         0.71372549, 0.69411765],\n",
       "        [0.25098039, 0.58431373, 0.58431373, ..., 0.70980392,\n",
       "         0.6745098 , 0.63921569],\n",
       "        [0.23921569, 0.55686275, 0.56862745, ..., 0.57647059,\n",
       "         0.56470588, 0.56470588],\n",
       "        ...,\n",
       "        [0.03921569, 0.01176471, 0.01960784, ..., 0.02352941,\n",
       "         0.01176471, 0.05882353],\n",
       "        [0.01568627, 0.00784314, 0.00392157, ..., 0.00784314,\n",
       "         0.00392157, 0.00784314],\n",
       "        [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157,\n",
       "         0.00392157, 0.00392157]],\n",
       "\n",
       "       [[0.40784314, 0.42745098, 0.42745098, ..., 0.39607843,\n",
       "         0.47058824, 0.48627451],\n",
       "        [0.41960784, 0.55294118, 0.53333333, ..., 0.47058824,\n",
       "         0.49411765, 0.51764706],\n",
       "        [0.42352941, 0.55686275, 0.53333333, ..., 0.54901961,\n",
       "         0.54901961, 0.54901961],\n",
       "        ...,\n",
       "        [0.36078431, 0.3372549 , 0.34117647, ..., 0.34117647,\n",
       "         0.33333333, 0.37254902],\n",
       "        [0.34117647, 0.33333333, 0.32941176, ..., 0.33333333,\n",
       "         0.32941176, 0.3372549 ],\n",
       "        [0.32941176, 0.32941176, 0.32941176, ..., 0.32941176,\n",
       "         0.32941176, 0.32941176]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        , ..., 1.        ,\n",
       "         1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        ,\n",
       "         1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        ,\n",
       "         1.        , 1.        ],\n",
       "        ...,\n",
       "        [1.        , 1.        , 1.        , ..., 1.        ,\n",
       "         1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        ,\n",
       "         1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        , ..., 1.        ,\n",
       "         1.        , 1.        ]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = train_imgs[0]\n",
    "\n",
    "new_arr = np.moveaxis(arr, -1, 0)\n",
    "\n",
    "new_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d1e73f74c8ec7a1671e8a50a2cf4a7de1dd968f28e814f9d8c3d6c3acdbc158"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
